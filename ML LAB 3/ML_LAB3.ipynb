{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ms1V5R72HWJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad61be1-501d-4f4c-a522-1dd109aff730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.375\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the Mean Squared Error (MSE) between true and predicted values.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (numpy array): Array of true values.\n",
        "    y_pred (numpy array): Array of predicted values.\n",
        "\n",
        "    Returns:\n",
        "    float: The Mean Squared Error.\n",
        "    \"\"\"\n",
        "    # Ensure inputs are numpy arrays\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calculate the squared differences\n",
        "    squared_differences = (y_true - y_pred) ** 2\n",
        "\n",
        "    # Calculate the mean of the squared differences\n",
        "    mse = np.mean(squared_differences)\n",
        "\n",
        "    return mse\n",
        "\n",
        "# Example usage\n",
        "y_true = [3, -0.5, 2, 7]\n",
        "y_pred = [2.5, 0.0, 2, 8]\n",
        "\n",
        "mse_value = mean_squared_error(y_true, y_pred)\n",
        "print(f\"Mean Squared Error: {mse_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def gradientdescent(X, y_true, w, LR, num_iterations):\n",
        "    cost_history = []\n",
        "    m = len(y_true)\n",
        "\n",
        "    # Iterate through the specified number of iterations\n",
        "    for _ in range(num_iterations):\n",
        "        # Make predictions\n",
        "        y_pred = X.dot(w)\n",
        "\n",
        "        # Calculate the gradient\n",
        "        gradient = (1 / m) * X.T.dot(y_pred - y_true)\n",
        "\n",
        "        # Update the weights\n",
        "        w = w - LR * gradient\n",
        "\n",
        "        # Calculate the cost (Mean Squared Error)\n",
        "        cost = (1 / (2 * m)) * np.sum((y_pred - y_true) ** 2)\n",
        "\n",
        "        # Append the cost to the history\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return w, cost_history\n",
        "\n",
        "# Example usage:\n",
        "# Prepare the data\n",
        "X = np.array([[1, 1], [1, 2], [1, 3]])  # Feature matrix (including bias term as 1 in the first column)\n",
        "y = np.array([1, 2, 3])  # True labels\n",
        "w = np.array([0.0, 0.0])  # Initial parameters (theta_0, theta_1)\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.1\n",
        "iterations = 1000\n",
        "\n",
        "# Run gradient descent\n",
        "w, cost_history = gradientdescent(X, y, w, learning_rate, iterations)\n",
        "\n",
        "print(\"Optimized theta:\", w)\n",
        "print(\"Final cost:\", cost_history[-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXRiTt_ZR5Kf",
        "outputId": "3c79aad7-0777-4fdd-8d4b-eadbfdd4befa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized theta: [2.06458287e-06 9.99999092e-01]\n",
            "Final cost: 3.132257388267102e-13\n"
          ]
        }
      ]
    }
  ]
}